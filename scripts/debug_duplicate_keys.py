# debug_duplicate_keys.py
# é™¤éŒ¯é‡è¤‡ä¸»éµå•é¡Œ
# ===================

import pandas as pd
import os

try:
    from config import OUTPUT_CSV_PATH, INPUT_DIR, COLUMN_MAPPING
except ImportError:
    print("âŒ éŒ¯èª¤ï¼šç„¡æ³•å¾ config.py å°å…¥è¨­å®šã€‚")
    exit()

def clean_column_names(df):
    """æ¸…ç†æ¬„ä½åç¨±"""
    cleaned_columns = {}
    for col in df.columns:
        cleaned_col = col.replace('\n', '').replace('\r', '').strip()
        
        if 'è‹¥æ‚¨æ˜¯è‡ªè¡Œé…é€è«‹ä½¿ç”¨å¾Œæ–¹è¦çš®å°ˆç·šå’ŒåŒ…è£¹æŸ¥è©¢ç¢¼è¯ç¹«è²·å®¶' in cleaned_col:
            cleaned_col = 'æ”¶ä»¶è€…é›»è©±'
        elif 'è«‹è¤‡è£½ä¸‹æ–¹å®Œæ•´ç·¨è™Ÿæä¾›çµ¦æ‚¨é…åˆçš„ç‰©æµå•†ç•¶åšè¯çµ¡é›»è©±' in cleaned_col:
            cleaned_col = 'è¦çš®å°ˆç·šå’ŒåŒ…è£¹æŸ¥è©¢ç¢¼'
        
        cleaned_columns[col] = cleaned_col
    
    df.rename(columns=cleaned_columns, inplace=True)
    return df

def create_robust_composite_key(df):
    """å»ºç«‹è¤‡åˆä¸»éµ"""
    key_components = [
        df['order_sn'].fillna('').astype(str).str.strip(),
        df['product_sku_variation'].fillna('NULL_SKU').astype(str).str.strip().replace('', 'NULL_SKU'),
        df['product_name'].fillna('').astype(str).str.strip()
    ]
    df['composite_key'] = pd.Series(zip(*key_components)).str.join('|||')
    return df

def debug_key_generation():
    """é™¤éŒ¯ä¸»éµç”Ÿæˆå•é¡Œ"""
    print("ğŸ” é™¤éŒ¯è¤‡åˆä¸»éµç”Ÿæˆå•é¡Œ")
    print("=" * 60)
    
    # 1. è®€å–ç¾æœ‰ä¸»æª”
    if not os.path.exists(OUTPUT_CSV_PATH):
        print("âŒ ä¸»æª”ä¸å­˜åœ¨")
        return
    
    df_old = pd.read_csv(OUTPUT_CSV_PATH, keep_default_na=False, dtype=str)
    print(f"ğŸ“„ ä¸»æª”è¼‰å…¥: {len(df_old)} ç­†è³‡æ–™")
    
    # 2. è®€å–æ–°çš„ Excel æª”æ¡ˆ
    excel_files = [f for f in os.listdir(INPUT_DIR) if f.endswith('.xlsx')]
    if not excel_files:
        print("âŒ æ²’æœ‰æ‰¾åˆ° Excel æª”æ¡ˆ")
        return
    
    excel_path = os.path.join(INPUT_DIR, excel_files[0])
    df_new = pd.read_excel(excel_path, dtype=str)
    df_new = clean_column_names(df_new)
    df_new.rename(columns=COLUMN_MAPPING, inplace=True)
    
    print(f"ğŸ“„ æ–°æª”è¼‰å…¥: {len(df_new)} ç­†è³‡æ–™")
    
    # 3. ç¯©é¸ç›¸åŒæ—¥æœŸç¯„åœçš„è³‡æ–™
    # è™•ç†æ—¥æœŸ
    df_new['order_date'] = pd.to_datetime(
        df_new['order_sn'].str.slice(0, 6),
        format='%y%m%d',
        errors='coerce'
    ).dt.date
    
    df_old['order_date_parsed'] = pd.to_datetime(df_old['order_date'], errors='coerce').dt.date
    
    # ç¢ºå®šæ–°è³‡æ–™çš„æ—¥æœŸç¯„åœ
    new_date_min = df_new['order_date'].min()
    new_date_max = df_new['order_date'].max()
    print(f"ğŸ“… æ–°è³‡æ–™æ—¥æœŸç¯„åœ: {new_date_min} åˆ° {new_date_max}")
    
    # ç¯©é¸èˆŠè³‡æ–™ä¸­ç›¸åŒæ—¥æœŸç¯„åœçš„éƒ¨åˆ†
    mask_same_range = (
        (df_old['order_date_parsed'] >= new_date_min) & 
        (df_old['order_date_parsed'] <= new_date_max)
    )
    df_old_same_range = df_old[mask_same_range].copy()
    print(f"ğŸ“… ä¸»æª”ä¸­ç›¸åŒæ—¥æœŸç¯„åœçš„è³‡æ–™: {len(df_old_same_range)} ç­†")
    
    # 4. ç”Ÿæˆè¤‡åˆä¸»éµ
    df_old_same_range = create_robust_composite_key(df_old_same_range)
    df_new = create_robust_composite_key(df_new)
    
    print(f"\nğŸ”‘ è¤‡åˆä¸»éµç”Ÿæˆçµæœ:")
    print(f"   èˆŠè³‡æ–™ (ç›¸åŒæ—¥æœŸç¯„åœ): {df_old_same_range['composite_key'].nunique()} å€‹å”¯ä¸€ä¸»éµ")
    print(f"   æ–°è³‡æ–™: {df_new['composite_key'].nunique()} å€‹å”¯ä¸€ä¸»éµ")
    
    # 5. æ¯”è¼ƒä¸»éµ
    old_keys = set(df_old_same_range['composite_key'])
    new_keys = set(df_new['composite_key'])
    
    print(f"\nğŸ”„ ä¸»éµæ¯”è¼ƒ:")
    print(f"   èˆŠè³‡æ–™ä¸»éµæ•¸: {len(old_keys)}")
    print(f"   æ–°è³‡æ–™ä¸»éµæ•¸: {len(new_keys)}")
    print(f"   å…±åŒä¸»éµæ•¸: {len(old_keys & new_keys)}")
    print(f"   èˆŠè³‡æ–™ç¨æœ‰: {len(old_keys - new_keys)}")
    print(f"   æ–°è³‡æ–™ç¨æœ‰: {len(new_keys - old_keys)}")
    
    # 6. åˆ†ææ¶ˆå¤±çš„ä¸»éµ
    disappeared_keys = old_keys - new_keys
    if disappeared_keys:
        print(f"\nâŒ æ¶ˆå¤±çš„ä¸»éµ ({len(disappeared_keys)} å€‹):")
        disappeared_records = df_old_same_range[df_old_same_range['composite_key'].isin(disappeared_keys)]
        
        for i, (idx, record) in enumerate(disappeared_records.iterrows()):
            if i >= 5:  # åªé¡¯ç¤ºå‰5å€‹
                print(f"   ... é‚„æœ‰ {len(disappeared_records) - 5} ç­†")
                break
            
            print(f"\n   {i+1}. è¨‚å–®: {record.get('order_sn', 'N/A')}")
            print(f"      å•†å“: {record.get('product_name', 'N/A')[:50]}...")
            print(f"      SKU: {record.get('product_sku_variation', 'N/A')}")
            print(f"      è¤‡åˆä¸»éµ: {record['composite_key']}")
            
            # æª¢æŸ¥æ˜¯å¦åœ¨æ–°è³‡æ–™ä¸­æœ‰ç›¸ä¼¼çš„è¨˜éŒ„
            similar_new = df_new[
                (df_new['order_sn'] == record.get('order_sn', '')) &
                (df_new['product_name'] == record.get('product_name', ''))
            ]
            
            if len(similar_new) > 0:
                print(f"      ğŸ” æ–°è³‡æ–™ä¸­æ‰¾åˆ°ç›¸ä¼¼è¨˜éŒ„:")
                for _, new_record in similar_new.iterrows():
                    print(f"         æ–°SKU: {new_record.get('product_sku_variation', 'N/A')}")
                    print(f"         æ–°ä¸»éµ: {new_record['composite_key']}")
                    
                    # æ¯”è¼ƒå·®ç•°
                    if record.get('product_sku_variation', '') != new_record.get('product_sku_variation', ''):
                        print(f"         â— SKU ä¸åŒ: '{record.get('product_sku_variation', '')}' vs '{new_record.get('product_sku_variation', '')}'")
    
    # 7. æª¢æŸ¥è³‡æ–™é¡å‹å•é¡Œ
    print(f"\nğŸ”¬ è³‡æ–™é¡å‹åˆ†æ:")
    
    # æª¢æŸ¥ SKU æ¬„ä½çš„è³‡æ–™é¡å‹
    old_sku_types = df_old_same_range['product_sku_variation'].apply(type).value_counts()
    new_sku_types = df_new['product_sku_variation'].apply(type).value_counts()
    
    print(f"   èˆŠè³‡æ–™ SKU é¡å‹: {dict(old_sku_types)}")
    print(f"   æ–°è³‡æ–™ SKU é¡å‹: {dict(new_sku_types)}")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æµ®é»æ•¸ç²¾åº¦å•é¡Œ
    old_sku_sample = df_old_same_range['product_sku_variation'].dropna().head(5).tolist()
    new_sku_sample = df_new['product_sku_variation'].dropna().head(5).tolist()
    
    print(f"\n   èˆŠè³‡æ–™ SKU ç¯„ä¾‹: {old_sku_sample}")
    print(f"   æ–°è³‡æ–™ SKU ç¯„ä¾‹: {new_sku_sample}")

if __name__ == "__main__":
    debug_key_generation()